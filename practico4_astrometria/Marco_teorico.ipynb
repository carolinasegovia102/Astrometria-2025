{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f05d5270",
   "metadata": {},
   "source": [
    "# Marco Teórico\n",
    "\n",
    "## 1. Inferencia Bayesiana\n",
    "\n",
    "La **inferencia bayesiana** es un método estadístico que permite estimar los valores más probables de los parámetros de un modelo a partir de los datos observados y del conocimiento previo que se tenga sobre ellos.  \n",
    "Se basa en el **teorema de Bayes**, que establece la relación entre la probabilidad *a posteriori* y la *a priori*:\n",
    "\n",
    "$$\n",
    "p(\\phi | d, m) = \\frac{p(d | \\phi, m)\\, p(\\phi | m)}{p(d | m)}\n",
    "$$\n",
    "\n",
    "donde:\n",
    "\n",
    "- $d$: conjunto de datos observados,  \n",
    "- $m$: modelo asumido,  \n",
    "- $\\phi$: vector de parámetros del modelo,  \n",
    "- $p(d | \\phi, m)$: **verosimilitud** o *likelihood*, mide qué tan bien el modelo reproduce los datos,  \n",
    "- $p(\\phi | m)$: **prior** o distribución *a priori*, refleja el conocimiento previo sobre los parámetros,  \n",
    "- $p(d | m)$: **evidencia**, factor de normalización que asegura que la probabilidad posterior esté correctamente normalizada.\n",
    "\n",
    "El objetivo de la inferencia bayesiana es determinar la **distribución posterior** $p(\\phi | d, m)$, que combina la información aportada por los datos con el conocimiento previo sobre los parámetros.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Función de Likelihood\n",
    "\n",
    "La **función de verosimilitud** cuantifica la probabilidad de observar los datos dados unos parámetros específicos del modelo.  \n",
    "Si los errores son independientes y gaussianos, se escribe como:\n",
    "\n",
    "$\n",
    "p(d | \\phi, m) \\propto \\exp \\left[-\\frac{1}{2} \\sum_i \\left(\\frac{d_i - m_i(\\phi)}{\\sigma_i}\\right)^2 \\right]\n",
    "$\n",
    "\n",
    "donde $d_i$ son los datos observados, $m_i(\\phi)$ los valores predichos por el modelo y $\\sigma_i$ el error de cada observación.  \n",
    "En este caso, maximizar el *likelihood* equivale a **minimizar los cuadrados residuales**, recuperando el método clásico de mínimos cuadrados.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Priors o Distribuciones a Priori\n",
    "\n",
    "Los **priors** reflejan el conocimiento o suposición inicial sobre los parámetros antes de observar los datos.  \n",
    "Algunos tipos comunes son:\n",
    "\n",
    "- **Prior plano (uniforme)**: todos los valores son igualmente probables dentro de un rango.  \n",
    "  $p(\\phi) = \\text{cte}$  \n",
    "- **Prior gaussiano**: se asume que los parámetros tienen una media y una desviación conocidas:  \n",
    "  $p(\\phi) \\propto \\exp\\left[-\\frac{(\\phi - \\mu)^2}{2\\sigma^2}\\right]$\n",
    "\n",
    "La elección del prior puede influir en el resultado de la inferencia, especialmente cuando los datos son escasos o ruidosos.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Métodos Monte Carlo y Cadenas de Markov (MCMC)\n",
    "\n",
    "En muchos casos, la integral de normalización (la evidencia) y la forma exacta de la distribución posterior no pueden calcularse de manera analítica.  \n",
    "Para ello se utilizan los **métodos de Monte Carlo**, que permiten **muestrear** la distribución posterior mediante simulaciones aleatorias.\n",
    "\n",
    "Una **cadena de Markov Monte Carlo (MCMC)** genera una secuencia de muestras $\\{\\phi_1, \\phi_2, ..., \\phi_N\\}$ donde cada nuevo valor depende únicamente del anterior, pero con una probabilidad que garantiza que, a largo plazo, la distribución de las muestras coincide con la distribución posterior buscada.\n",
    "\n",
    "Esto permite estimar la forma de $p(\\phi | d, m)$ y obtener intervalos de confianza o correlaciones entre parámetros.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Algoritmo de Metropolis–Hastings\n",
    "\n",
    "El **algoritmo de Metropolis–Hastings** es uno de los métodos más utilizados para generar cadenas MCMC.  \n",
    "Su procedimiento básico es:\n",
    "\n",
    "1. **Elegir un punto inicial** $\\phi_0$.  \n",
    "2. **Proponer un nuevo punto** $\\phi' = \\phi_t + \\delta$ a partir de una distribución de propuesta $$q(\\phi'|\\phi_t)$$.  \n",
    "3. **Calcular la probabilidad de aceptación**:\n",
    "\n",
    "   $$\n",
    "   r = \\frac{p(d | \\phi')\\, p(\\phi')\\, q(\\phi_t|\\phi')}{p(d | \\phi_t)\\, p(\\phi_t)\\, q(\\phi'|\\phi_t)}\n",
    "   $$\n",
    "\n",
    "4. **Aceptar o rechazar**:\n",
    "   - Si $u < \\min(1, r)$ (con $u \\sim U[0,1]$), aceptar el nuevo punto.\n",
    "   - Si no, mantener el punto anterior.\n",
    "\n",
    "5. Repetir el proceso hasta completar la longitud deseada de la cadena.\n",
    "\n",
    "Luego de un período inicial llamado **burn-in**, la cadena converge hacia la distribución posterior y puede usarse para estimar los parámetros y sus incertidumbres.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Convergencia y Mezclado de Cadenas\n",
    "\n",
    "Una buena simulación MCMC requiere que la cadena:\n",
    "- Explore correctamente todo el espacio de parámetros (**mezclado**, *mixing*).  \n",
    "- Sea independiente del punto inicial (**convergencia**).\n",
    "\n",
    "Para verificar esto, se analizan gráficamente:\n",
    "- El *trace plot* (parámetro vs iteración),  \n",
    "- El *likelihood* vs parámetro,  \n",
    "- Las distribuciones marginales obtenidas de la cadena,  \n",
    "- La distancia entre cadenas independientes inicializadas en diferentes puntos.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Gradiente Descendente\n",
    "\n",
    "El **método del gradiente descendente** es una técnica de optimización utilizada para encontrar los mínimos de una función, en este caso el mínimo de la función de *negative log-likelihood*.  \n",
    "A partir de una posición inicial $\\phi_0$, se actualizan los parámetros según:\n",
    "\n",
    "$\\phi_{t+1} = \\phi_t - \\eta \\, \\nabla L(\\phi_t)$\n",
    "\n",
    "donde $\\eta$ es la **tasa de aprendizaje** (*learning rate*) y $\\nabla L(\\phi_t)$ el gradiente de la función de pérdida respecto a los parámetros.\n",
    "\n",
    "Este método es eficiente cuando la función es suave y derivable, pero puede presentar problemas de convergencia si $\\eta$ no se elige adecuadamente o si el *likelihood* tiene múltiples mínimos locales.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Enfoque Bayesiano vs Frecuentista\n",
    "\n",
    "- El **enfoque frecuentista** interpreta la probabilidad como la frecuencia relativa de un evento en repeticiones infinitas.  \n",
    "  Los parámetros son fijos pero desconocidos, y los datos son aleatorios.\n",
    "\n",
    "- El **enfoque bayesiano** trata los parámetros como variables aleatorias con distribuciones de probabilidad que se actualizan al incorporar nuevos datos.  \n",
    "  La probabilidad expresa el grado de creencia sobre los valores de los parámetros.\n",
    "\n",
    "Este contraste se refleja en la interpretación de los resultados:  \n",
    "un intervalor frecuentista indica la frecuencia esperada de contener el parámetro verdadero, mientras que un intervalo bayesiano indica el rango de valores más probables dado el conjunto de datos.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astrometria",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
